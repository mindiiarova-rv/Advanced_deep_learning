{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center>\n",
        "<h1><br/></h1>\n",
        "<h1>INF581A: Advanced Deep Learning</h1>\n",
        "<h2>Lab 5: Transformer and Transfer Learning</h2>\n",
        "\n",
        "<h5>Tuesday, February 04, 2025</h5>\n",
        "<br>\n",
        "</center>\n",
        "\n",
        "<hr style=\"border:10px solid gray\"> </hr>\n",
        "<p style=\"text-align: justify;\">\n",
        "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit to Moodle a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>February 11\n",
        ", 2025 11:59 AM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late → -5 pts; ]24, 48] hours late → -10 pts; > 48 hours late → not graded (zero).\n",
        "</p>\n",
        "<hr style=\"border:5px solid gray\"> </hr>\n",
        "\n",
        "<h3><b>1. Introduction:</b></h2>\n",
        "<p style=\"text-align: justify;\">\n",
        "Transfer learning that is, solving tasks with models that have been pretrained on very large amounts of data, was a game changer in many deep learning tasks. In NLP, while annotated data are scarce, raw text is virtually unlimited and readily available. Thus, the ability to learn good representations from plain text could greatly improve general natural language understanding. Learning without labels is enabled via self-supervised learning, a setting in which a system learns to predict part of its input from other parts of its input.\n",
        "\n",
        "<p>One way to realise this pre-training is to use <i>generative pre-training</i> <a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\" target='_blank'>[1]</a> of a language model. In this pre-training phase, the model will learn to predict the next tokens in a sequence given the previous ones.</p>\n",
        "<p>Thus, this phase does not require any type of annotations apart from the input text itself. Once the language model is sufficiently pre-trained, it can be fine-tuned on supervised tasks while requiring minimal changes to its architecture (replacing the classification head).</p>\n",
        "\n",
        "In this lab we will:\n",
        "<ul>\n",
        "    <li>Implement and pretrain a language model with transformer architecture.</li>\n",
        "    <li>Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.</li>\n",
        "    <li>Compare the performance of the pretrained model to a model trained from scratch.</li>\n",
        "</ul>\n",
        "\n",
        "<h3><b>2. The Model:</b></h3>\n",
        "<p style=\"text-align: justify;\">\n",
        "\n",
        "Our model is based on Transformers<a href=\"https://arxiv.org/abs/1706.03762\" target='_blank'>[2]</a>. While the Transformer is a model that follows the encoder-decoder structure, it is possible to use only the encoder part (as in BERT) or the decoder part (as in gpt) to perform some specific tasks. In this notebook, we use a multi-layer Transformer decoder for the language model. Fortunatly, PyTorch recent releases include a standard transformer blocks that can be easily used and adapted.\n",
        "\n",
        "Let's start by implementing the model. The different layers used in this model are the following:\n",
        "\n",
        "- The embedding layer\n",
        "- Positional Embedding\n",
        "- The transformer layers\n",
        "- Linear layer for decoding and classification\n",
        "<center>\n",
        "<img src='https://am3pap003files.storage.live.com/y4m6sN7mGXA8_lmRiUuuAAbecrSrMa1IumytUCiEJEkIKuoKV2uNoqTmo6mU_PadFeMESJTRjNbM3Q9qIRMiXLMxPDBdKKFC5cX5UFslx44IxVGXBAI7Cipp5A38tVQdwrioDNyWAMIbYb7dQTXoa0T6oRDBl1kgGn2D9JV8wuna3Jhrsd3TgPQNZZnoO9ZpmaN?width=815&height=680&cropmode=none' alt=\"Drawing\" width= '500px'/>\n",
        "\n",
        "The same model can be used for language modeling and classification by just replacing the last layer in the model. This is why we split our model into two modules:\n",
        "\n",
        "- base module: which consists of the 3 first layers.\n",
        "- classifier module: which consists of the last layer.\n",
        "\n",
        "After the pretraining, the parameters of the base model can be \"transferred\" to the model used in the classfication task, while the classifier module should be replaced by a new head initialized randomly.\n",
        "\n",
        "Some of the code is adapted from this nice tutorial: <a href=\"https://pytorch.org/tutorials/beginner/transformer_tutorial.html\" target=\"_blank\">https://pytorch.org/tutorials/beginner/transformer_tutorial.html</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 1: </b><br>\n",
        "Fill in the gaps in the `TransformerModel()` class to implement the described model.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "roNlBhkJPIrk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=nhid,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=nhid,  # Typically 4 times the model dimension\n",
        "            dropout=dropout\n",
        "        )\n",
        "        #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)  # Add positional encoding\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)  # Base Transformer model\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "\n",
        "        x = self.base(src, src_mask)\n",
        "        #x = x.mean(dim=0)\n",
        "        #fill me\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  # for a more in depth explanation we encourage you to read:\n",
        "  # https://medium.com/swlh/elegant-intuitions-behind-positional-encodings-dc48b4a4a5d1\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 1 (4 points): </b><br>\n",
        "What is the role of the square mask in our implementation? What about the positional encoding?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H1FwuPBuPyFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 1: </b><br>\n",
        "Your answer here\n",
        "\n",
        "In tasks like language modeling, where the model predicts the next token in a sequence, we must prevent the model from \"cheating\" by looking ahead at future tokens.\n",
        "This mask ensures that, at each step, the model only attends to past and current tokens, not future tokens.\n",
        "\n",
        "Unlike RNNs, Transformers do not have inherent sequence order awareness.\n",
        "The self-attention mechanism treats all tokens simultaneously, meaning it doesn’t know which word comes first, second, etc. We add unique positional encodings to each token's embedding.\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "IB9wyvMUP8FZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 2 (2 points): </b><br>\n",
        "Why do we have to replace the classification head? What is the main difference between the <i>language modeling</i> and the <i>classification</i> tasks?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "q7PIyZg4U4oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 2: </b><br>\n",
        "Your answer here\n",
        "\n",
        "We replace the classification head because language modeling and classification have different objectives. In language modeling, the model predicts the next word in a sequence, with the final layer mapping hidden states to vocabulary logits (ntoken). In classification, the model processes the entire text and predicts a category, so the final layer maps hidden states to class logits (nclasses).\n",
        "\n",
        "The key difference is in handling output features: language modeling uses the last token's representation, while classification applies mean pooling over all tokens to obtain a single feature vector. This ensures the model captures the full context before making a final prediction.\n",
        "\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "3EU6M747VMEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 3 (6 points): </b><br>\n",
        "How many trainable parameters does the model have in the case of <br>\n",
        "<ul>\n",
        "<font color='red'>\n",
        "    <li><i>language modeling</i> task.</li>\n",
        "    <li><i>classification</i> task.</li>\n",
        "</ul>\n",
        "Please detail your answer. You can omit the biases and the parameters of normalization layers.<br>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "eIHvBUqGVeH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 3: </b><br>\n",
        "Your answer here\n"
      ],
      "metadata": {
        "id": "LLrionbqV3Sf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b10c415-f56d-4a59-8f3a-3eb6c314312b"
      },
      "source": [
        "ntokens = 100  # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## 3.Vocabulary and Tokenization\n",
        "\n",
        "To train the language model, the text in our corpus should be first tokenized. We use sentencepiece <a href=\"https://github.com/google/sentencepiece\">https://github.com/google/sentencepiece</a> that implements byte-pair-encoding (BPE), a sub-word tokenization algorithm.<br>\n",
        "The vocabulay is given in <code>dict.txt</code> file. Let's load it, and map each token to a unique index.<br>\n",
        "\n",
        "In our experiments we use datasets that are already tokenized.\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 2: </b><br>\n",
        "Fill in the gaps to create a <code>token2ind</code> and <code>ind2token</code> mapping dictionaries\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975d845f-8c03-47d6-a8b5-44728329e842"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-10 19:49:00--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "\rdict.txt              0%[                    ]       0  --.-KB/s               \rdict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-10 19:49:01 (15.3 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e7c551-29d5-4070-c4c7-7e1ef7725bc0"
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3}  # First 4 indices are reserved\n",
        "\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()  # Extract the first word from each line\n",
        "        token2ind[word] = idx + 4  # Assign an index starting from 4\n",
        "\n",
        "# Creating the reverse mapping\n",
        "ind2token = {v: k for k, v in token2ind.items()}\n",
        "\n",
        "# Printing the word at index 1111\n",
        "print(ind2token[1111])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "## 4.Data Loader\n",
        "We use the <code>DataLoader</code> class, to load our dataset and generate the mini-batches used in the training. <code>get_loader()</code> returns a <code>DataLoader</code>  object, which is an iterable over data samples. The data loader can return mini-batches for language modeling or sequence classification based on the <code>task</code> argument that we pass to <code>get_loader()</code> function. Currently the function supports <i>language_modeling</i> and <i>classification</i> tasks.<br>\n",
        "\n",
        "For the <i>language_modeling</i> task, both the input and the target are batches of sequences. In fact, the target is basically a shifted version of\n",
        "the input, in such a way that each token is predicted given all previous tokens. For example, for a sequence A B C D: <br>\n",
        "<b>Input:</b><code>\\<sos\\></code>A B C D<br>\n",
        "<b>Output:</b>A B C D<code>\\<eos\\></code><br>\n",
        "\n",
        "For the <i>classification</i> task,\n",
        "the input is a batch of sequences and\n",
        "the target is a batch of scalar labels.<br>\n",
        "For more information about data loaders check: <a href=\"https://pytorch.org/docs/stable/data.html\">https://pytorch.org/docs/stable/data.html</a>\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 3: </b><br>\n",
        "Fill in the gap inside <code>Dataset</code> class in order to create the input sequence\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind.get(\"<sos>\", 3)] + [\n",
        "            self.token2ind.get(token, self.token2ind.get(\"<oov>\", 3)) for token in sequence\n",
        "        ]\n",
        "\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## 5.The Training\n",
        "In this section we will implement a <code>train()</code> function that trains our model for one epoch. As we said, in this lab we will use a language modeling objective in\n",
        "the pretraining phase. Given the previous tokens in a sequence,\n",
        "the model will try to predict\n",
        "the next one. The same function can be used for both pretraining and fine-tuning phase.<br>\n",
        "\n",
        "The training procedure is as follows:<br>\n",
        "1. Iterate over the data-loader.<br>\n",
        "2. In each iteration perform one forward pass.<br>\n",
        "3. Compute\n",
        "the loss through back-propagation.<br>\n",
        "4. update\n",
        "the parameters of your model using sgd.<br>\n",
        "5. repeat for <i>n</i> epochs<br>\n",
        "\n",
        "<b>N.B:</b>  While in\n",
        "the <i>language_modeling</i> task all\n",
        "the vectors at\n",
        "the output of\n",
        "the base model are used, in\n",
        "the <i>classification</i> task we only use\n",
        "the vector representing\n",
        "the last token to perform\n",
        "the prediction.<br>\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 4: </b><br>\n",
        "Fill in the gaps in <code>train()</code> function.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            # last vector only\n",
        "           output = output[-1]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1].view(-1).to(device)\n",
        "        target = target.to(device)\n",
        "        loss = torch.nn.functional.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "source": [
        "ntokens = len(token2ind)  # Total number of unique tokens in vocabulary\n",
        "\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a37cee-2a7f-4328-eb03-73963c90efcf"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-10 19:58:34--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.1’\n",
            "\n",
            "\rpretraining_subset.   0%[                    ]       0  --.-KB/s               \rpretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-02-10 19:58:35 (141 MB/s) - ‘pretraining_subset.txt.1’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cf5eb3-4184-49d8-d097-e181846612cc"
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 2.87713 | ppl   17.763\n",
            "| epoch   1 |  1000/ 3125 steps | loss 2.63475 | ppl   13.940\n",
            "| epoch   1 |  1500/ 3125 steps | loss 2.57785 | ppl   13.169\n",
            "| epoch   1 |  2000/ 3125 steps | loss 2.50241 | ppl   12.212\n",
            "| epoch   1 |  2500/ 3125 steps | loss 2.46524 | ppl   11.766\n",
            "| epoch   1 |  3000/ 3125 steps | loss 2.44115 | ppl   11.486\n",
            "| epoch   2 |   500/ 3125 steps | loss 2.29912 | ppl    9.965\n",
            "| epoch   2 |  1000/ 3125 steps | loss 2.27185 | ppl    9.697\n",
            "| epoch   2 |  1500/ 3125 steps | loss 2.29539 | ppl    9.928\n",
            "| epoch   2 |  2000/ 3125 steps | loss 2.25783 | ppl    9.562\n",
            "| epoch   2 |  2500/ 3125 steps | loss 2.23729 | ppl    9.368\n",
            "| epoch   2 |  3000/ 3125 steps | loss 2.23613 | ppl    9.357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## 6. Text Generation\n",
        "Being trained on a language modeling objective, our model can be used in the inference mode to generate/complete sentences. However, the pretraining phase takes a lot of time compared to the fine-tuning. For example, <a href=\"https://arxiv.org/pdf/1911.03894.pdf\">CamemBERT</a><sub>base</sub> <sup>[1]</sup> was pretrained for 24 hours on 256 Nvidia V100 GPUs and <a href=\"https://arxiv.org/pdf/2010.12321.pdf\">BARThez</a> <sup>[2]</sup> was pretrained for 60h on 128 Nvidia V100 GPUs!<br>\n",
        "\n",
        "Of course, we don't have enough time and resources to efficiently pretrain our model, so instead we will load the weights from a checkpoint that has been pre-trained for 12 hours on 1 GPU.<br>\n",
        "\n",
        "Take a look here: <a href=\"https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\">https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training</a><br>\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 5: </b><br>\n",
        "Implement the function <code>infer_next_tokens()</code> that takes as input a string <code>sent</code> and an integer <code>max_len</code> and returns a completion of the input sentence. The generation should stop when the model generates <code>&lt;eos&gt;</code> or the length of the generated sentence reaches <code>max_len</code>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ff745c-9c29-4d0e-a289-b764aa89edb8"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-10 21:16:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.1’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   256MB/s    in 0.3s    \n",
            "\n",
            "2025-02-10 21:16:28 (256 MB/s) - ‘pretrained_model_4layers.pt.1’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-35-76a40ce8b80e>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('pretrained_model_4layers.pt')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b6b777-4750-451c-984c-cbaba75b8c6d"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "--2025-02-10 21:16:35--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-10 21:16:36 (27.6 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = s.encode_as_pieces(\"Coucou tout le monde\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5iqDT80v9Gx",
        "outputId": "b644e696-dec7-466d-a5da-a4949b26f21b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁C', 'oucou', '▁tout', '▁le', '▁monde']\n",
            "Coucou tout le monde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces]\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1)\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind.get(el, token2ind['<oov>']) for el in sent_pieces]\n",
        "\n",
        "    source_tensor = torch.tensor(source).to(device).reshape(-1, 1)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        src_mask = model.base.generate_square_subsequent_mask(source_tensor.size(0)).to(device)\n",
        "\n",
        "        out = model(source_tensor, src_mask)\n",
        "        next_token_ind = out[-1].argmax(-1).item()\n",
        "\n",
        "        if next_token_ind == token2ind['<eos>']:\n",
        "            break\n",
        "\n",
        "        source.append(next_token_ind)\n",
        "        source_tensor = torch.tensor(source).to(device).reshape(-1, 1)\n",
        "\n",
        "    generated_sentence = [ind2token[token] for token in source[1:]]\n",
        "\n",
        "    return \" \".join(generated_sentence)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "11252f7f-21b4-4ea0-ed77-1774b885ddd7"
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁Bonjour ▁les ▁gens ▁qui ▁ont ▁été ▁très ▁accueillants ▁et ▁sympathiques .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "## 7. Supervised task\n",
        "It's time to train the model on the supervised task, which is in our case sentiment analysis. It consists of predicting whether a book review is a positive or a negative review. The model will be trained in 2 settings.<br>\n",
        "<ul>\n",
        "    <li>Training from scratch: All model parameters are randomly initialized.</li>\n",
        "    <li>Transfer learning: Only the classification head is trained from scratch, all other parameters are copied from the pre-trained model.</li>\n",
        "</ul>\n",
        "\n",
        "The training function is already implemented. However, to evaluate the model at each epoch we have to implement a function that computes the accuracy of the model on the validation set.<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af39637c-4b29-4a26-8d49-f154157a524f"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-10 21:18:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "\rtrain.review.spm      0%[                    ]       0  --.-KB/s               \rtrain.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-10 21:18:28 (30.1 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2025-02-10 21:18:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-10 21:18:29 (50.7 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2025-02-10 21:18:29--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-10 21:18:29 (35.7 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2025-02-10 21:18:29--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-10 21:18:29 (71.2 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 6: </b><br>\n",
        "Implement the <code>accuracy()</code> function. This function takes as input a <code>data_loader</code> and returns an float.<br>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "vKMRmZD9abvd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "import torch\n",
        "\n",
        "def evaluate_accuracy(data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input_data = data[0].to(device)\n",
        "            target = data[1].to(device)\n",
        "\n",
        "            src_mask = model.base.generate_square_subsequent_mask(input_data.size(0)).to(device)\n",
        "\n",
        "            output = model(input_data, src_mask)\n",
        "\n",
        "            output = output[-1]\n",
        "\n",
        "            predictions = output.argmax(dim=-1)\n",
        "\n",
        "            correct += (predictions == target).sum().item()\n",
        "            total += target.numel()\n",
        "\n",
        "    return correct / total\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98987f44-7186-450c-a82e-16c0be95c3ca"
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.78012 | ppl    2.182\n",
            "| epoch   1 |   100/  200 steps | loss 0.71874 | ppl    2.052\n",
            "| epoch   1 |   150/  200 steps | loss 0.78973 | ppl    2.203\n",
            "| epoch   2 |    50/  200 steps | loss 0.64996 | ppl    1.915\n",
            "| epoch   2 |   100/  200 steps | loss 0.68668 | ppl    1.987\n",
            "| epoch   2 |   150/  200 steps | loss 0.64704 | ppl    1.910\n",
            "| epoch   3 |    50/  200 steps | loss 0.40431 | ppl    1.498\n",
            "| epoch   3 |   100/  200 steps | loss 0.42426 | ppl    1.528\n",
            "| epoch   3 |   150/  200 steps | loss 0.36212 | ppl    1.436\n",
            "| epoch   4 |    50/  200 steps | loss 0.19733 | ppl    1.218\n",
            "| epoch   4 |   100/  200 steps | loss 0.13272 | ppl    1.142\n",
            "| epoch   4 |   150/  200 steps | loss 0.24715 | ppl    1.280\n",
            "| epoch   5 |    50/  200 steps | loss 0.00671 | ppl    1.007\n",
            "| epoch   5 |   100/  200 steps | loss 0.02948 | ppl    1.030\n",
            "| epoch   5 |   150/  200 steps | loss 0.03949 | ppl    1.040\n",
            "| epoch   6 |    50/  200 steps | loss 0.00292 | ppl    1.003\n",
            "| epoch   6 |   100/  200 steps | loss 0.00513 | ppl    1.005\n",
            "| epoch   6 |   150/  200 steps | loss 0.02311 | ppl    1.023\n",
            "| epoch   7 |    50/  200 steps | loss 0.00024 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00020 | ppl    1.000\n",
            "| epoch   7 |   150/  200 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00474 | ppl    1.005\n",
            "| epoch   8 |   150/  200 steps | loss 0.00024 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-f09076582a3e>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |    50/  200 steps | loss 0.80480 | ppl    2.236\n",
            "| epoch   1 |   100/  200 steps | loss 0.66268 | ppl    1.940\n",
            "| epoch   1 |   150/  200 steps | loss 0.61384 | ppl    1.848\n",
            "| epoch   2 |    50/  200 steps | loss 0.50355 | ppl    1.655\n",
            "| epoch   2 |   100/  200 steps | loss 0.43845 | ppl    1.550\n",
            "| epoch   2 |   150/  200 steps | loss 0.44500 | ppl    1.560\n",
            "| epoch   3 |    50/  200 steps | loss 0.35999 | ppl    1.433\n",
            "| epoch   3 |   100/  200 steps | loss 0.37118 | ppl    1.449\n",
            "| epoch   3 |   150/  200 steps | loss 0.40596 | ppl    1.501\n",
            "| epoch   4 |    50/  200 steps | loss 0.26032 | ppl    1.297\n",
            "| epoch   4 |   100/  200 steps | loss 0.29233 | ppl    1.340\n",
            "| epoch   4 |   150/  200 steps | loss 0.26526 | ppl    1.304\n",
            "| epoch   5 |    50/  200 steps | loss 0.18797 | ppl    1.207\n",
            "| epoch   5 |   100/  200 steps | loss 0.13913 | ppl    1.149\n",
            "| epoch   5 |   150/  200 steps | loss 0.19947 | ppl    1.221\n",
            "| epoch   6 |    50/  200 steps | loss 0.08402 | ppl    1.088\n",
            "| epoch   6 |   100/  200 steps | loss 0.10124 | ppl    1.107\n",
            "| epoch   6 |   150/  200 steps | loss 0.15401 | ppl    1.167\n",
            "| epoch   7 |    50/  200 steps | loss 0.04984 | ppl    1.051\n",
            "| epoch   7 |   100/  200 steps | loss 0.02805 | ppl    1.028\n",
            "| epoch   7 |   150/  200 steps | loss 0.05744 | ppl    1.059\n",
            "| epoch   8 |    50/  200 steps | loss 0.01084 | ppl    1.011\n",
            "| epoch   8 |   100/  200 steps | loss 0.03389 | ppl    1.034\n",
            "| epoch   8 |   150/  200 steps | loss 0.02979 | ppl    1.030\n",
            "| epoch   9 |    50/  200 steps | loss 0.01707 | ppl    1.017\n",
            "| epoch   9 |   100/  200 steps | loss 0.00355 | ppl    1.004\n",
            "| epoch   9 |   150/  200 steps | loss 0.00248 | ppl    1.002\n",
            "| epoch  10 |    50/  200 steps | loss 0.01325 | ppl    1.013\n",
            "| epoch  10 |   100/  200 steps | loss 0.00659 | ppl    1.007\n",
            "| epoch  10 |   150/  200 steps | loss 0.00225 | ppl    1.002\n",
            "| epoch  11 |    50/  200 steps | loss 0.00168 | ppl    1.002\n",
            "| epoch  11 |   100/  200 steps | loss 0.00045 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00574 | ppl    1.006\n",
            "| epoch  12 |    50/  200 steps | loss 0.01408 | ppl    1.014\n",
            "| epoch  12 |   100/  200 steps | loss 0.01249 | ppl    1.013\n",
            "| epoch  12 |   150/  200 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.02581 | ppl    1.026\n",
            "| epoch  13 |   100/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00019 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00051 | ppl    1.001\n",
            "| epoch  14 |   100/  200 steps | loss 0.00012 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.01601 | ppl    1.016\n",
            "| epoch  15 |    50/  200 steps | loss 0.01187 | ppl    1.012\n",
            "| epoch  15 |   100/  200 steps | loss 0.01569 | ppl    1.016\n",
            "| epoch  15 |   150/  200 steps | loss 0.00035 | ppl    1.000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 7: </b><br>\n",
        "Visualize the evolution of the accuracy of the model in function of the epoch in both settings.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "KNyMCGV-a269"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(from_scratch_valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hccPuHsgwqIg",
        "outputId": "3fe957f6-0b6e-47aa-e2b3-fa435c088fb3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pretrained_valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsJLBjM6wrkc",
        "outputId": "490b60e4-cd6c-478f-95c1-cc2a39b2493b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "f742ea18-83b3-4dec-e5fd-22da15a8603d"
      },
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, 16))\n",
        "\n",
        "accuracy_language_modeling = pretrained_valid_acc\n",
        "accuracy_classification = from_scratch_valid_acc\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, accuracy_language_modeling, marker='o', label=\"Language Modeling\")\n",
        "plt.plot(epochs, accuracy_classification, marker='s', label=\"Classification\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Evolution of Model Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 4 (4 points): </b><br>\n",
        "Interpret the results.\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "L10PpUpxa86n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 4: </b><br>\n",
        "Your answer here\n",
        "\n",
        "\n",
        "The language modeling accuracy starts high (~0.75) and gradually improves, stabilizing around 0.80. This indicates that the model effectively learns word sequences and context over epochs. However, slight fluctuations suggest overfitting or sensitivity to certain patterns in the data.\n",
        "\n",
        "The classification model starts with lower accuracy (~0.52) but improves rapidly within the first few epochs, reaching ~0.75. This sharp increase suggests that the model quickly captures discriminative features for classification but later plateaus, indicating that additional training provides diminishing returns\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "I7n4omIlbDhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 5 (4 points): </b><br>\n",
        "What is one of the limitations of the language modeling objective used in this notebook, compared to the masked language model objective introduced in <a href=\"https://arxiv.org/abs/1810.04805\" target=\"_blank\">Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.</a><br>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "QTIlxIVBbDrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 5: </b><br>\n",
        "Your answer here\n",
        "\n",
        "One major limitation of the standard language modeling objective used in this notebook is that it trains the model in an auto-regressive fashion, meaning the model predicts the next word sequentially from left to right. This means it can only leverage past context when making predictions.\n",
        "\n",
        "In contrast, the Masked Language Model (MLM) objective used in BERT allows the model to learn from both left and right context by randomly masking certain words in the input and predicting them using surrounding words. This makes MLM a bidirectional approach, capturing richer contextual relationships, leading to better performance in downstream NLP tasks such as classification, question answering, and named entity recognition.\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "UsxL_yQHbEOh"
      }
    }
  ]
}